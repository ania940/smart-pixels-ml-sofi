{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a335ce-e1c3-4820-9d1e-e6e9d51c17bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 00:19:06.374569: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-21 00:19:06.374623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-21 00:19:06.375646: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-21 00:19:06.382361: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-21 00:19:09.858227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Training notebook for 1Dconv 16x16 Full model with filtered Dataset3sr and input dig.\n",
    "# Note that it is currently configured to work with 20 timeslices\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from qkeras import *\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "pi = 3.14159265359\n",
    "\n",
    "maxval=1e9\n",
    "minval=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d28df7-f0bf-4178-8cce-5fe8a6af0021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 00:19:27.612995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1186 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB MIG 1g.5gb, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "from full_1D.Full_nll4 import *\n",
    "#from models.models import *\n",
    "from full_1D.Full1D_model2 import *\n",
    "import utils\n",
    "from OptimizedDataGenerator_v2 import OptimizedDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7505eedb-d216-4121-8654-4dad365ecf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "val_batch_size = 5000\n",
    "train_file_size = 68\n",
    "val_file_size = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2251a-a53d-4375-89ae-e0305bf796aa",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222d825c-62e1-474d-bd1a-a283fbe55947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_in_directory(directory_path):\n",
    "    try:\n",
    "        return len([f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Directory not found: {directory_path}\")\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656f2556-8545-4bf2-9af5-38bdca49e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_dir = \"/depot/cms/users/callea/largerWindowPreliminary/dataset_3sr_16x16_50x12P5_parquets/\"\n",
    "\n",
    "data_directory_path = os.path.join(dataset_base_dir, \"train_filtered\")\n",
    "data_directory_path_2 = os.path.join(dataset_base_dir, \"test_filtered\")\n",
    "\n",
    "tfrecords_dir_train = \"/depot/cms/users/callea/largerWindowPreliminary/dataset_3sr_16x16_50x12P5_parquets/train_filtered/\"\n",
    "tfrecords_dir_validation = \"/depot/cms/users/callea/largerWindowPreliminary/dataset_3sr_16x16_50x12P5_parquets/test_filtered/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3aa6998-d4fd-46b8-907a-87aaa517e4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in data directory: 80\n"
     ]
    }
   ],
   "source": [
    "# Count files in both directories\n",
    "data_files_count = count_files_in_directory(data_directory_path)\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of files in data directory: {data_files_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24651937-a99e-4149-9071-98a127c3432f",
   "metadata": {},
   "source": [
    "Create a new tfrecord can avoid the problem of not converging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8750be76-6792-47eb-85ae-465e70785a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files...: 100%|██████████| 12/12 [00:12<00:00,  1.07s/it]\n",
      "Saving batches as TFRecords: 100%|██████████| 14/14 [00:21<00:00,  1.56s/it]\n",
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved successfully ast /home/callea/TFrecords_3sr_qf_full_20t/val/metadata.json\n",
      "Loading metadata from /home/callea/TFrecords_3sr_qf_full_20t/val/metadata.json\n"
     ]
    }
   ],
   "source": [
    "validation_generator = OptimizedDataGenerator(\n",
    "    dataset_base_dir = data_directory_path_2,\n",
    "    is_directory_recursive = False,\n",
    "    batch_size = val_batch_size,\n",
    "    file_count = val_file_size,\n",
    "    to_standardize = True,\n",
    "    include_y_local = False,\n",
    "    # Labels you want to extract\n",
    "    labels_list = ['x-midplane', 'y-midplane', 'cotAlpha', 'cotBeta'],\n",
    "    # Input shape for the model (time slices, height, width)\n",
    "    input_shape = (20, 16, 16),\n",
    "    transpose = (0, 2, 3, 1),\n",
    "    shuffle = False,\n",
    "    files_from_end = False,\n",
    "    \n",
    "    # New parameters specific to this generator\n",
    "    tfrecords_dir = tfrecords_dir_validation,\n",
    "    tfrecords_dir_save = \"/home/callea/TFrecords_3sr_qf_full_20t/val\", \n",
    "    use_time_stamps = list(range(20)),\n",
    "    #[0, 19],\n",
    "    # Specific time stamps to use\n",
    "    quantize = True,  # Whether to use quantization during loading\n",
    "    max_workers = 2  # For parallel processing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e67cc9-2d89-4ff5-89e4-0db5283de3dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files...: 100%|██████████| 68/68 [01:18<00:00,  1.16s/it]\n",
      "Saving batches as TFRecords: 100%|██████████| 74/74 [02:06<00:00,  1.71s/it]\n",
      "WARNING:root:Quantization is True in data generator. This may affect model performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved successfully ast /home/callea/TFrecords_3sr_qf_full_20t/train/metadata.json\n",
      "Loading metadata from /home/callea/TFrecords_3sr_qf_full_20t/train/metadata.json\n"
     ]
    }
   ],
   "source": [
    "training_generator = OptimizedDataGenerator(\n",
    "    # Base directory where your parquet files are located\n",
    "    dataset_base_dir = data_directory_path,\n",
    "    is_directory_recursive = False,\n",
    "    batch_size = batch_size,\n",
    "    file_count = train_file_size,\n",
    "    to_standardize = True,\n",
    "    include_y_local = False,\n",
    "    # Labels you want to extract\n",
    "    labels_list = ['x-midplane', 'y-midplane', 'cotAlpha', 'cotBeta'],\n",
    "    # Input shape for the model (time slices, height, width)\n",
    "    input_shape = (20, 16, 16),\n",
    "    transpose = (0, 2, 3, 1),\n",
    "    shuffle = False,\n",
    "    files_from_end = True,  # Using files from the end of the list\n",
    "    \n",
    "    # New parameters specific to this generator\n",
    "    tfrecords_dir = tfrecords_dir_train,\n",
    "    tfrecords_dir_save = \"/home/callea/TFrecords_3sr_qf_full_20t/train\", \n",
    "    use_time_stamps = list(range(20)),\n",
    "    #[0, 19],  # Specific time stamps to use\n",
    "    quantize = True,  # Whether to use quantization during loading\n",
    "    max_workers = 2  # For parallel processing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34144708-e322-4ef3-9636-7fda63781c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"smrtpxl_regression_full\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_pxls/ (InputLayer)    [(None, 16, 16, 20)]         0         []                            \n",
      "                                                                                                  \n",
      " avg_pooling_2d_proj_x (Ave  (None, 16, 1, 20)            0         ['input_pxls/[0][0]']         \n",
      " ragePooling2D)                                                                                   \n",
      "                                                                                                  \n",
      " avg_pooling_2d_proj_y (Ave  (None, 1, 16, 20)            0         ['input_pxls/[0][0]']         \n",
      " ragePooling2D)                                                                                   \n",
      "                                                                                                  \n",
      " reshape_proj_x (Reshape)    (None, 16, 20)               0         ['avg_pooling_2d_proj_x[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " reshape_proj_y (Reshape)    (None, 16, 20)               0         ['avg_pooling_2d_proj_y[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_proj_x (Conv1D)      (None, 14, 5)                305       ['reshape_proj_x[0][0]']      \n",
      "                                                                                                  \n",
      " conv1d_proj_y (Conv1D)      (None, 14, 5)                305       ['reshape_proj_y[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 28, 5)                0         ['conv1d_proj_x[0][0]',       \n",
      "                                                                     'conv1d_proj_y[0][0]']       \n",
      "                                                                                                  \n",
      " activation_tanh_1 (Activat  (None, 28, 5)                0         ['concatenate[0][0]']         \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 140)                  0         ['activation_tanh_1[0][0]']   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 16)                   2256      ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " activation_tanh_2 (Activat  (None, 16)                   0         ['dense_1[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 16)                   272       ['activation_tanh_2[0][0]']   \n",
      "                                                                                                  \n",
      " activation_tanh_3 (Activat  (None, 16)                   0         ['dense_2[0][0]']             \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 8)                    136       ['activation_tanh_3[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3274 (12.79 KB)\n",
      "Trainable params: 3274 (12.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (16, 16, 20)\n",
    "model = CreateModel_full(input_shape)  # Use Full model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba75da98-3d92-4513-8d83-a4e175190a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a much higher learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3),  # 10x higher!\n",
    "    loss=custom_diag_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2eea790-5e90-484c-9fe1-7b5df8164aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint = '%08x' % random.randrange(16**8)\n",
    "os.makedirs(\"trained_models\", exist_ok=True)\n",
    "base_dir = f'./trained_models/model-{fingerprint}-checkpoints'\n",
    "os.makedirs(base_dir, exist_ok=True)  \n",
    "checkpoint_filepath = base_dir + '/weights.{epoch:02d}-t{loss:.2f}-v{val_loss:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b883b73-461c-4352-ae0d-2c0613c440cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./trained_models/model-1ba7272a-checkpoints/weights.{epoch:02d}-t{loss:.2f}-v{val_loss:.2f}.hdf5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6e2dda7-a746-4c51-9981-d585407aaaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ba7272a\n"
     ]
    }
   ],
   "source": [
    "print(fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12415516-7c30-4ad5-9bda-109cc78b7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, Callback\n",
    "\n",
    "early_stopping_patience = 50\n",
    "\n",
    "class CustomModelCheckpoint(ModelCheckpoint):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        checkpoints = [f for f in os.listdir(base_dir) if f.startswith('weights')]\n",
    "        if len(checkpoints) > 1:\n",
    "            checkpoints.sort()\n",
    "            for checkpoint in checkpoints[:-1]:\n",
    "                os.remove(os.path.join(base_dir, checkpoint))\n",
    "\n",
    "es = EarlyStopping(patience=early_stopping_patience, restore_best_weights=True)\n",
    "\n",
    "mcp = CustomModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_freq='epoch',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(f'{base_dir}/training_log.csv', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7d34e25-0f7a-4e78-b4c3-416627402dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanMonitorCallback(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print('NaN loss detected, terminating training')\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "# Add this to your callbacks list\n",
    "nan_monitor = NanMonitorCallback()\n",
    "callbacks = [mcp, csv_logger, nan_monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace645c-2d24-40f9-8048-b9379c870d63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 00:23:29.391412: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 00:23:32.159125: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-07-21 00:23:32.273042: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-07-21 00:23:33.190645: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f89831ac730 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-07-21 00:23:33.190709: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB MIG 1g.5gb, Compute Capability 8.0\n",
      "2025-07-21 00:23:33.202687: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753050213.324132  850563 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 7172.5288\n",
      "Epoch 1: val_loss improved from inf to -4289.93506, saving model to ./trained_models/model-1ba7272a-checkpoints/weights.01-t7172.53-v-4289.94.hdf5\n",
      "74/74 [==============================] - 29s 341ms/step - loss: 7172.5288 - val_loss: -4289.9351\n",
      "Epoch 2/1000\n",
      "74/74 [==============================] - ETA: 0s - loss: -10463.6299\n",
      "Epoch 2: val_loss improved from -4289.93506 to -14859.66211, saving model to ./trained_models/model-1ba7272a-checkpoints/weights.02-t-10463.63-v-14859.66.hdf5\n",
      "74/74 [==============================] - 20s 273ms/step - loss: -10463.6299 - val_loss: -14859.6621\n",
      "Epoch 3/1000\n",
      "74/74 [==============================] - ETA: 0s - loss: -18130.7930\n",
      "Epoch 3: val_loss improved from -14859.66211 to -19149.19922, saving model to ./trained_models/model-1ba7272a-checkpoints/weights.03-t-18130.79-v-19149.20.hdf5\n",
      "74/74 [==============================] - 24s 326ms/step - loss: -18130.7930 - val_loss: -19149.1992\n",
      "Epoch 4/1000\n",
      "29/74 [==========>...................] - ETA: 12s - loss: -20668.8242"
     ]
    }
   ],
   "source": [
    "# Now use it in model.fit()\n",
    "history = model.fit(\n",
    "    x=training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks,\n",
    "    epochs=1000,\n",
    "    shuffle=False,\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 kernel (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
